# Introduction

Implement a simple rate limiter

# How to start

## 1. Start Redis

docker run -d -p 6379:6379 redis:8-alpine

## 2. Run the program

```sh
go mod tidy
go run main.go
```

# Rate Limiting Algorithms

## 1. Fixed Window Counter

### The Idea
Count requests in fixed time buckets. Reset when time's up.

```
Minute 1        Minute 2
[â– â– â– â– â– ]         [â– â– ]
5 requests      2 requests
Reset at 60s â†’  Start fresh
```

### How It Works
1. Request comes in
2. Increment counter
3. If counter â‰¤ limit: âœ… Allow
4. If counter > limit: âŒ Block
5. After 60 seconds: counter resets to 0

### The Boundary Problem âš ï¸

```
00:55 â†’ Make 5 requests âœ… (allowed)
01:01 â†’ Make 5 more âœ… (new window, allowed)

Problem: 10 requests in 6 seconds.
But limit is 5 per minute.
```

Users can game the system by timing requests at window boundaries.

### Pros & Cons

âœ… **Pros:**
- Very simple
- Low memory (one counter per user)
- Fast

âŒ **Cons:**
- Boundary problem (can get 2Ã— limit)
- Sudden resets feel arbitrary

### When to Use
- Internal tools
- Quick prototypes
- Low-stakes applications


## 2. Sliding Window Log

### The Idea
Remember the timestamp of EVERY request. Count how many are in the last 60 seconds.

```
Timestamps: [10s, 15s, 20s, 45s, 70s]
Current time: 75s
Window: Last 60s = [15s to 75s]

Count:
10s âŒ Too old
15s âœ… In window
20s âœ… In window
45s âœ… In window
70s âœ… In window

Total: 4 requests in window
```

### How It Works
1. New request at time T
2. Delete timestamps older than (T - 60 seconds)
3. Count remaining timestamps
4. If count < limit: âœ… Allow and save timestamp
5. If count â‰¥ limit: âŒ Block

### Example
Limit: 5 per 60 seconds

```
10s â†’ Save [10] â†’ âœ…
15s â†’ Save [10, 15] â†’ âœ…
20s â†’ Save [10, 15, 20] â†’ âœ…
25s â†’ Save [10, 15, 20, 25] â†’ âœ…
30s â†’ Save [10, 15, 20, 25, 30] â†’ âœ…
35s â†’ Count = 5 â†’ âŒ BLOCKED

70s â†’ Remove <10s â†’ [15, 20, 25, 30]
     â†’ Count = 4 â†’ âœ… Allow
```

### No Boundary Problem

```
55s â†’ 5 requests [55, 55, 55, 55, 55]
61s â†’ Check window [1s to 61s]
     â†’ All 5 from 55s still there
     â†’ Count = 5 â‰¥ 5
     â†’ âŒ BLOCKED
```

### Pros & Cons

âœ… **Pros:**
- 100% accurate
- No boundary problem
- Truly sliding window

âŒ **Cons:**
- High memory (stores every request)
- Slower (more operations)
- Not scalable for millions of users

### When to Use
- Banking systems
- Payment processing
- When perfect accuracy is critical
- Low-medium traffic

## 3. Sliding Window Counter

### The Idea
Use TWO counters (previous + current window) and estimate the count.

```
Previous [0-60s]: 10 requests
Current [60-120s]: 4 requests
Now at 90s (halfway into current)

Math:
- We're 50% into current window
- From previous: 10 Ã— 50% = 5
- From current: 4 Ã— 100% = 4
- Estimate: 5 + 4 = 9 requests
```

### Visual

```
Previous    Current
[10 req]    [4 req]
  â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  0s   60s    120s
           â†‘
         90s (we are here)

Looking back 60s = [30s to 90s]
- Last 30s of previous: ~5 requests
- First 30s of current: 4 requests
- Total estimate: 9 requests
```

### How It Works
1. Get previous window count
2. Get current window count
3. Calculate % into current window
4. Estimate = previous Ã— (1-%) + current Ã— 100%
5. If estimate < limit: âœ… Allow

### Accuracy

Not perfect, but very accurate

Why not 100%?
- Assumes even distribution
- Actual requests might cluster

But good enough for most cases

### Pros & Cons

âœ… **Pros:**
- Good accuracy
- Low memory (only 2 counters)
- Fast
- Mostly solves boundary problem

âŒ **Cons:**
- Slight estimation error
- More complex math

### When to Use
- **Production default choice**
- High traffic APIs
- Most modern systems
- When you need balance

## 4. Token Bucket

### The Idea
Bucket holds tokens. Each request costs 1 token. Tokens refill continuously.

```
Start: [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 5 tokens

Request â†’ -1 token
       [ğŸª™ğŸª™ğŸª™ğŸª™Â·]

Time passes â†’ +tokens
       [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] Full!

5 quick requests:
       [Â·Â·Â·Â·Â·] Empty!

Next request â†’ âŒ No tokens!

Wait... â†’ refill
       [ğŸª™ğŸª™Â·Â·Â·]

Request â†’ âœ… Allowed
       [ğŸª™Â·Â·Â·Â·]
```

### How It Works

**State:**
- tokens: current token count
- last_refill: when we last updated

**On each request:**
1. Calculate time passed
2. Add tokens: time Ã— refill_rate
3. Cap at capacity
4. If tokens â‰¥ 1: âœ… Allow, subtract 1
5. If tokens < 1: âŒ Block

### Burst Handling

Scenario: User idle for 10 seconds

Bucket fills up: [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™]

User makes 5 requests instantly:
All allowed

This is a "burst", bucket was full from waiting.

### Why It's Popular

Allows bursts but controls average rate

Average rate: 60 tokens/minute
But can burst up to capacity instantly

Good for:
- APIs (user saves up tokens)
- File uploads (one big file = many tokens)
- Bursty traffic patterns

### Pros & Cons

âœ… **Pros:**
- Allows bursts (good UX)
- Smooth refilling
- Industry standard
- Flexible (different costs per request)

âŒ **Cons:**
- Needs atomic operations (Lua script)
- Slightly complex
- Float math

### When to Use
- **Public APIs** (most popular choice)
- When bursts are OK
- AWS, GitHub, Stripe all use this
- Modern applications

## Summary Table

| Algorithm | Complexity | Memory | Accuracy | Bursts | Production Ready |
|-----------|-----------|--------|----------|--------|------------------|
| Fixed Window | â­ Easy | Low | 50% | No | âŒ |
| Sliding Log | â­â­â­ Hard | High | 100% | No | âœ… Critical only |
| Sliding Counter | â­â­ Medium | Low | 95% | No | âœ… Yes |
| Token Bucket | â­â­ Medium | Low | 95% | Yes | âœ… Best default |

## Key Takeaways

1. **Fixed Window** = Simple but has boundary problem
2. **Sliding Log** = Perfect accuracy but expensive
3. **Sliding Counter** = Good balance for high traffic
4. **Token Bucket** = Most popular, allows bursts
